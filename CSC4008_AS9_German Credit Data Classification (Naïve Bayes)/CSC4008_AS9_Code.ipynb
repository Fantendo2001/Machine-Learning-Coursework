{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSC4008 Assignment 9\n",
    "### Jiang Jingxin 117020119"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Credit Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\"credit-g.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 21 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   checking_status         1000 non-null   object\n",
      " 1   duration                1000 non-null   int64 \n",
      " 2   credit_history          1000 non-null   object\n",
      " 3   purpose                 1000 non-null   object\n",
      " 4   credit_amount           1000 non-null   int64 \n",
      " 5   savings_status          1000 non-null   object\n",
      " 6   employment              1000 non-null   object\n",
      " 7   installment_commitment  1000 non-null   int64 \n",
      " 8   personal_status         1000 non-null   object\n",
      " 9   other_parties           1000 non-null   object\n",
      " 10  residence_since         1000 non-null   int64 \n",
      " 11  property_magnitude      1000 non-null   object\n",
      " 12  age                     1000 non-null   int64 \n",
      " 13  other_payment_plans     1000 non-null   object\n",
      " 14  housing                 1000 non-null   object\n",
      " 15  existing_credits        1000 non-null   int64 \n",
      " 16  job                     1000 non-null   object\n",
      " 17  num_dependents          1000 non-null   int64 \n",
      " 18  own_telephone           1000 non-null   object\n",
      " 19  foreign_worker          1000 non-null   object\n",
      " 20  class                   1000 non-null   object\n",
      "dtypes: int64(7), object(14)\n",
      "memory usage: 164.2+ KB\n"
     ]
    }
   ],
   "source": [
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "checking_status             4\n",
       "duration                   33\n",
       "credit_history              5\n",
       "purpose                    10\n",
       "credit_amount             921\n",
       "savings_status              5\n",
       "employment                  5\n",
       "installment_commitment      4\n",
       "personal_status             4\n",
       "other_parties               3\n",
       "residence_since             4\n",
       "property_magnitude          4\n",
       "age                        53\n",
       "other_payment_plans         3\n",
       "housing                     3\n",
       "existing_credits            4\n",
       "job                         4\n",
       "num_dependents              2\n",
       "own_telephone               2\n",
       "foreign_worker              2\n",
       "class                       2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = raw_data.drop(columns=['class'])\n",
    "y = raw_data.loc[:,'class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Naïve Bayes Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self, pseudocount=1):\n",
    "        self.pseudocount = pseudocount\n",
    "    \n",
    "    def fit(self, X, y, numeric):\n",
    "        self._class = y.unique()\n",
    "        self._numeric_idx = list()\n",
    "        for i, col in enumerate(X.columns):\n",
    "            if numeric==[]:\n",
    "                break\n",
    "            if col in numeric:\n",
    "                self._numeric_idx.append(i)\n",
    "                numeric.remove(col)\n",
    "        self._prior = dict()\n",
    "        self._theta = list()\n",
    "        for label in self._class:\n",
    "            self._prior[label] = sum(y==label)/len(y)\n",
    "            x = X[y==label]\n",
    "            theta = [dict()for i in range(len(X.columns))]\n",
    "            i = 0\n",
    "            for idx in self._numeric_idx:\n",
    "                while i < idx:\n",
    "                    for attr in X.iloc[:,i].unique():\n",
    "                        theta[i][attr] = (sum(x.iloc[:,i]==attr)+1)/(len(x)+len(X.iloc[:,i].unique()))\n",
    "                    i += 1\n",
    "                theta[i]['mu'] = x.iloc[:,i].mean()\n",
    "                theta[i]['sigma'] = x.iloc[:,i].std()\n",
    "                i += 1\n",
    "            while i < len(X.columns):\n",
    "                for attr in X.iloc[:,i].unique():\n",
    "                    theta[i][attr] = (sum(x.iloc[:,i]==attr)+1)/(len(x)+len(X.iloc[:,i].unique()))\n",
    "                i += 1\n",
    "            self._theta.append(theta)  \n",
    "    \n",
    "    def predict(self,X):\n",
    "        if len(self._numeric_idx)>0:\n",
    "            from scipy.stats import norm\n",
    "        pred = list()\n",
    "        for row in range(len(X)):\n",
    "            x = X.loc[row]\n",
    "            Label = ''\n",
    "            Posterior = 0\n",
    "            for l, label in enumerate(self._class):\n",
    "                posterior = self._prior[label]\n",
    "                i = 0\n",
    "                for idx in self._numeric_idx:\n",
    "                    while i < idx:\n",
    "                        posterior *= self._theta[l][i][x[i]]\n",
    "                        i += 1\n",
    "                    posterior *= norm.pdf(x[i],self._theta[l][i]['mu'],self._theta[l][i]['sigma'])\n",
    "                    i += 1\n",
    "                while i < len(X.columns):\n",
    "                    posterior *= self._theta[l][i][x[i]]\n",
    "                    i += 1\n",
    "                if posterior > Posterior:\n",
    "                    Posterior = posterior\n",
    "                    Label = label\n",
    "            pred.append(Label)\n",
    "        pred = pd.Series(pred,name='predicted')     \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv(X, y, k=10, seed =None, numeric=['credit_amount','age','duration']):\n",
    "    from tqdm import tqdm\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    idx = np.arange(y.size) \n",
    "    np.random.shuffle(idx) \n",
    "    fold = np.array_split(idx,k) # split shuffled index into k folds\n",
    "    \n",
    "    pred = np.zeros_like(y)\n",
    "\n",
    "    # cross validation using k folds\n",
    "    for i in tqdm(range(k)):\n",
    "        test_idx = fold[i]\n",
    "        train_idx = np.setdiff1d(idx, test_idx)\n",
    "        mod = NaiveBayes()\n",
    "        mod.fit(X.loc[train_idx],y[train_idx],numeric=numeric.copy())\n",
    "        pred[test_idx] = mod.predict(X.loc[test_idx].reset_index(drop=True))\n",
    "    return pd.Series(pred,name='predicted') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(true,pred):\n",
    "    cm = pd.crosstab(true,pred)\n",
    "    TP = cm.iloc[1,1]\n",
    "    TN = cm.iloc[0,0]\n",
    "    FP = cm.iloc[0,1]\n",
    "    FN = cm.iloc[1,0]\n",
    "    precision = round(TP/ (TP+FP),3)\n",
    "    sensitivity = round(TP / (TP + FN), 3)\n",
    "    specificity = round(TN / (TN + FP), 3)\n",
    "    F_measure = round(2*precision*sensitivity/(precision + sensitivity),3)\n",
    "    print(\"\\n=== Detailed Accuracy ===\\n\")\n",
    "    print(\"Precision:\", precision,sep='\\t')\n",
    "    print(\"Sensitivity:\", sensitivity,sep='\\t')\n",
    "    print(\"Specificity:\", specificity,sep='\\t')\n",
    "    print(\"F_measure:\", F_measure,sep='\\t')\n",
    "    print(\"\\n=== Confusion Matrix ===\\n\")\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:04<00:00,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Detailed Accuracy ===\n",
      "\n",
      "Precision:\t0.801\n",
      "Sensitivity:\t0.866\n",
      "Specificity:\t0.497\n",
      "F_measure:\t0.832\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "\n",
      "predicted  bad  good\n",
      "class               \n",
      "bad        149   151\n",
      "good        94   606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred = cv(X,y,seed=1)\n",
    "evaluate(y,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2.1 Compare with Weka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:weka.core.jvm:Adding bundled jars\n",
      "DEBUG:weka.core.jvm:Classpath=['/Users/Jingxin/.pyenv/versions/3.6.10/envs/virtual/lib/python3.6/site-packages/javabridge/jars/rhino-1.7R4.jar', '/Users/Jingxin/.pyenv/versions/3.6.10/envs/virtual/lib/python3.6/site-packages/javabridge/jars/runnablequeue.jar', '/Users/Jingxin/.pyenv/versions/3.6.10/envs/virtual/lib/python3.6/site-packages/javabridge/jars/cpython.jar', '/Users/Jingxin/.pyenv/versions/virtual/lib/python3.6/site-packages/weka/lib/python-weka-wrapper.jar', '/Users/Jingxin/.pyenv/versions/virtual/lib/python3.6/site-packages/weka/lib/weka.jar']\n",
      "DEBUG:weka.core.jvm:MaxHeapSize=default\n",
      "DEBUG:weka.core.jvm:Package support disabled\n"
     ]
    }
   ],
   "source": [
    "import weka.core.jvm as jvm\n",
    "jvm.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weka.core.converters import Loader\n",
    "loader = Loader(classname=\"weka.core.converters.ArffLoader\")\n",
    "arff_data = loader.load_file(\"credit-g.arff\")\n",
    "arff_data.class_is_last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weka.classifiers import Classifier, Evaluation\n",
    "cls = Classifier(classname=\"weka.classifiers.bayes.NaiveBayes\")\n",
    "cls.build_classifier(arff_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Correctly Classified Instances         754               75.4    %\n",
      "Incorrectly Classified Instances       246               24.6    %\n",
      "Kappa statistic                          0.3813\n",
      "Mean absolute error                      0.2936\n",
      "Root mean squared error                  0.4201\n",
      "Relative absolute error                 69.8801 %\n",
      "Root relative squared error             91.6718 %\n",
      "Total Number of Instances             1000     \n",
      "\n",
      "=== Detailed Accuracy By Class ===\n",
      "\n",
      "                 TP Rate  FP Rate  Precision  Recall   F-Measure  MCC      ROC Area  PRC Area  Class\n",
      "                 0.864    0.503    0.800      0.864    0.831      0.385    0.787     0.891     good\n",
      "                 0.497    0.136    0.611      0.497    0.548      0.385    0.787     0.577     bad\n",
      "Weighted Avg.    0.754    0.393    0.743      0.754    0.746      0.385    0.787     0.797     \n",
      "\n",
      "=== Confusion Matrix ===\n",
      "\n",
      "   a   b   <-- classified as\n",
      " 605  95 |   a = good\n",
      " 151 149 |   b = bad\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from weka.core.classes import Random\n",
    "evaluation = Evaluation(arff_data)\n",
    "evl = evaluation.crossvalidate_model(cls, arff_data, 10, Random(1))\n",
    "print(evaluation.summary())\n",
    "print(evaluation.class_details())\n",
    "print(evaluation.matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "jvm.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2.2 Different k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 k = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:03<00:00,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Detailed Accuracy ===\n",
      "\n",
      "Precision:\t0.785\n",
      "Sensitivity:\t0.827\n",
      "Specificity:\t0.47\n",
      "F_measure:\t0.805\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "\n",
      "predicted  bad  good\n",
      "class               \n",
      "bad        141   159\n",
      "good       121   579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred = cv(X,y,k=2, seed=1)\n",
    "evaluate(y,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:03<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Detailed Accuracy ===\n",
      "\n",
      "Precision:\t0.796\n",
      "Sensitivity:\t0.86\n",
      "Specificity:\t0.487\n",
      "F_measure:\t0.827\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "\n",
      "predicted  bad  good\n",
      "class               \n",
      "bad        146   154\n",
      "good        98   602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred = cv(X,y,k=5, seed=1)\n",
    "evaluate(y,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Detailed Accuracy ===\n",
      "\n",
      "Precision:\t0.801\n",
      "Sensitivity:\t0.866\n",
      "Specificity:\t0.497\n",
      "F_measure:\t0.832\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "\n",
      "predicted  bad  good\n",
      "class               \n",
      "bad        149   151\n",
      "good        94   606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred = cv(X,y,k=10, seed=1)\n",
    "evaluate(y,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 k = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:06<00:00,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Detailed Accuracy ===\n",
      "\n",
      "Precision:\t0.802\n",
      "Sensitivity:\t0.873\n",
      "Specificity:\t0.497\n",
      "F_measure:\t0.836\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "\n",
      "predicted  bad  good\n",
      "class               \n",
      "bad        149   151\n",
      "good        89   611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred = cv(X,y,k=20, seed=1)\n",
    "evaluate(y,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 k = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:09<00:00,  5.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Detailed Accuracy ===\n",
      "\n",
      "Precision:\t0.799\n",
      "Sensitivity:\t0.866\n",
      "Specificity:\t0.493\n",
      "F_measure:\t0.831\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "\n",
      "predicted  bad  good\n",
      "class               \n",
      "bad        148   152\n",
      "good        94   606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred = cv(X,y,k=50, seed=1)\n",
    "evaluate(y,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.5 Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As k increases, the cross-validated performance first increases with k.\n",
    "\n",
    "When k gets larger (e.g. k=50), it may suffer from overfitting problem and the performance is not so good as before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2.3 Selection of Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  2.3.1 CfsSubsetEval (BestFirst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relation Name:  german_credit-weka.filters.supervised.attribute.AttributeSelection-Eweka.attributeSelection.CfsSubsetEval -P 1 -E 1-Sweka.attributeSelection.BestFirst -D 1 -N 5\n",
      "Num Instances:  1000\n",
      "Num Attributes: 4\n",
      "\n",
      "     Name                      Type  Nom  Int Real     Missing      Unique  Dist\n",
      "1 checking_status            Nom 100%   0%   0%     0 /  0%     0 /  0%     4 \n",
      "2 duration                   Num   0% 100%   0%     0 /  0%     5 /  1%    33 \n",
      "3 credit_history             Nom 100%   0%   0%     0 /  0%     0 /  0%     5 \n",
      "4 class                      Nom 100%   0%   0%     0 /  0%     0 /  0%     2 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from weka.filters import Filter\n",
    "from weka.attribute_selection import ASSearch, ASEvaluation\n",
    "\n",
    "flter = Filter(classname=\"weka.filters.supervised.attribute.AttributeSelection\")\n",
    "aseval = ASEvaluation(classname=\"weka.attributeSelection.CfsSubsetEval\", \n",
    "                      options=[\"-P\", \"1\", \"-E\", \"1\"])\n",
    "assearch = ASSearch(classname=\"weka.attributeSelection.BestFirst\", \n",
    "                    options=[\"-D\", \"1\", \"-N\", \"5\"])\n",
    "flter.set_property(\"evaluator\", aseval.jobject)\n",
    "flter.set_property(\"search\", assearch.jobject)\n",
    "flter.inputformat(arff_data)\n",
    "filtered = flter.filter(arff_data)\n",
    "print(filtered.summary(filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filtered = X[[\"checking_status\",\"duration\",\"credit_history\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 19.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Detailed Accuracy ===\n",
      "\n",
      "Precision:\t0.764\n",
      "Sensitivity:\t0.91\n",
      "Specificity:\t0.343\n",
      "F_measure:\t0.831\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "\n",
      "predicted  bad  good\n",
      "class               \n",
      "bad        103   197\n",
      "good        63   637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred = cv(X_filtered,y,k=50, seed=1,numeric=[\"duration\"])\n",
    "evaluate(y,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  2.3.2 CorrelationAttributeEval (Ranker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relation Name:  german_credit-weka.filters.supervised.attribute.AttributeSelection-Eweka.attributeSelection.CorrelationAttributeEval-Sweka.attributeSelection.Ranker -T -1.7976931348623157E308 -N -1\n",
      "Num Instances:  1000\n",
      "Num Attributes: 21\n",
      "\n",
      "     Name                      Type  Nom  Int Real     Missing      Unique  Dist\n",
      " 1 checking_status            Nom 100%   0%   0%     0 /  0%     0 /  0%     4 \n",
      " 2 duration                   Num   0% 100%   0%     0 /  0%     5 /  1%    33 \n",
      " 3 credit_amount              Num   0% 100%   0%     0 /  0%   847 / 85%   921 \n",
      " 4 savings_status             Nom 100%   0%   0%     0 /  0%     0 /  0%     5 \n",
      " 5 housing                    Nom 100%   0%   0%     0 /  0%     0 /  0%     3 \n",
      " 6 other_payment_plans        Nom 100%   0%   0%     0 /  0%     0 /  0%     3 \n",
      " 7 age                        Num   0% 100%   0%     0 /  0%     1 /  0%    53 \n",
      " 8 credit_history             Nom 100%   0%   0%     0 /  0%     0 /  0%     5 \n",
      " 9 foreign_worker             Nom 100%   0%   0%     0 /  0%     0 /  0%     2 \n",
      "10 purpose                    Nom 100%   0%   0%     0 /  0%     0 /  0%    10 \n",
      "11 installment_commitment     Num   0% 100%   0%     0 /  0%     0 /  0%     4 \n",
      "12 personal_status            Nom 100%   0%   0%     0 /  0%     0 /  0%     4 \n",
      "13 property_magnitude         Nom 100%   0%   0%     0 /  0%     0 /  0%     4 \n",
      "14 employment                 Nom 100%   0%   0%     0 /  0%     0 /  0%     5 \n",
      "15 existing_credits           Num   0% 100%   0%     0 /  0%     0 /  0%     4 \n",
      "16 own_telephone              Nom 100%   0%   0%     0 /  0%     0 /  0%     2 \n",
      "17 job                        Nom 100%   0%   0%     0 /  0%     0 /  0%     4 \n",
      "18 other_parties              Nom 100%   0%   0%     0 /  0%     0 /  0%     3 \n",
      "19 num_dependents             Num   0% 100%   0%     0 /  0%     0 /  0%     2 \n",
      "20 residence_since            Num   0% 100%   0%     0 /  0%     0 /  0%     4 \n",
      "21 class                      Nom 100%   0%   0%     0 /  0%     0 /  0%     2 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from weka.filters import Filter\n",
    "from weka.attribute_selection import ASSearch, ASEvaluation\n",
    "\n",
    "flter = Filter(classname=\"weka.filters.supervised.attribute.AttributeSelection\")\n",
    "aseval = ASEvaluation(classname=\"weka.attributeSelection.CorrelationAttributeEval\")\n",
    "assearch = ASSearch(classname=\"weka.attributeSelection.Ranker\", \n",
    "                    options=[\"-T\", \"-1.7976931348623157E308\", \"-N\", \"-1\"]) \n",
    "flter.set_property(\"evaluator\", aseval.jobject)\n",
    "flter.set_property(\"search\", assearch.jobject)\n",
    "flter.inputformat(arff_data)\n",
    "filtered = flter.filter(arff_data)\n",
    "print(filtered.summary(filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filtered = X[[\"checking_status\",\"duration\",\"credit_amount\",\"savings_status\",\"housing\"]] # top 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 16.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Detailed Accuracy ===\n",
      "\n",
      "Precision:\t0.759\n",
      "Sensitivity:\t0.889\n",
      "Specificity:\t0.34\n",
      "F_measure:\t0.819\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "\n",
      "predicted  bad  good\n",
      "class               \n",
      "bad        102   198\n",
      "good        78   622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred = cv(X_filtered,y,k=50, seed=1,numeric=[\"duration\",\"credit_amount\"])\n",
    "evaluate(y,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  2.3.3 Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attributes selection is a trading off process: fewer predictor and less information, more predictor and more noise in data.\n",
    "\n",
    "After selection, the sensitivity increase while other measures drops. \n",
    "\n",
    "However, even with smaller set of predictors (3 of 20), the results are roughly the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagging(X,y,k,seed=None,numeric = ['credit_amount','age','duration']):\n",
    "    from tqdm import tqdm\n",
    "    np.random.seed(seed)\n",
    "    pred = np.zeros_like(y)\n",
    "    for i in tqdm(range(k)):\n",
    "        idx = np.random.choice(len(X),len(X),replace=True)\n",
    "        X_train = X.loc[idx].reset_index(drop=True)\n",
    "        y_train = y.loc[idx].reset_index(drop=True)\n",
    "        mod = NaiveBayes()\n",
    "        mod.fit(X_train,y_train,numeric=numeric.copy())\n",
    "        pred += (mod.predict(X)==\"good\")\n",
    "    pred = pd.Series(np.where(pred > k//2,'good','bad'),name='predicted')\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:37<00:00,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Detailed Accuracy ===\n",
      "\n",
      "Precision:\t0.814\n",
      "Sensitivity:\t0.873\n",
      "Specificity:\t0.533\n",
      "F_measure:\t0.842\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "\n",
      "predicted  bad  good\n",
      "class               \n",
      "bad        160   140\n",
      "good        89   611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred = bagging(X,y,k=10,seed=1)\n",
    "evaluate(y,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After using the bagging strategy, the results improve quite a lot with higher accuracy comparing to the original one.\n",
    "\n",
    "This is because the composite model reduces the variance of individual errors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('virtual': venv)",
   "language": "python",
   "name": "python361064bitvirtualvenv17b58f63dd9043ed85793e7f8be03798"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
