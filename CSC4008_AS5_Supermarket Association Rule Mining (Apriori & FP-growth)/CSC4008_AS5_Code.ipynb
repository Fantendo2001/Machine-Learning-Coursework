{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSC4008 Assignment 5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### @arthor: JIANG, Jingxin 117020119"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Macros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_supermarket = pd.read_excel(\"AS5 supermarket.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 Replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "supermarket = raw_supermarket.replace({\"?\":0,\"high\\n\":\"high\",\"low\\n\":\"low\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 Add column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = pd.read_excel(\"AS5 supermarket_attribute_name.xlsx\",header=None)[1]\n",
    "names = [col.strip() for col in names]\n",
    "supermarket.columns = names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.3 Drop columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop department columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "department_col = [col for col in supermarket.columns if col.startswith('department')]\n",
    "supermarket = supermarket.drop(columns=department_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop non-frequent columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "supermarket = supermarket.drop(columns=supermarket.columns[supermarket.sum()==0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop `high`/`low` class column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "supermarket = supermarket.drop(columns=['total'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Data Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4627 entries, 0 to 4626\n",
      "Data columns (total 100 columns):\n",
      " #   Column              Non-Null Count  Dtype\n",
      "---  ------              --------------  -----\n",
      " 0   grocery misc        4627 non-null   int64\n",
      " 1   baby needs          4627 non-null   int64\n",
      " 2   bread and cake      4627 non-null   int64\n",
      " 3   baking needs        4627 non-null   int64\n",
      " 4   juice-sat-cord-ms   4627 non-null   int64\n",
      " 5   tea                 4627 non-null   int64\n",
      " 6   biscuits            4627 non-null   int64\n",
      " 7   canned fish-meat    4627 non-null   int64\n",
      " 8   canned fruit        4627 non-null   int64\n",
      " 9   canned vegetables   4627 non-null   int64\n",
      " 10  breakfast food      4627 non-null   int64\n",
      " 11  cigs-tobacco pkts   4627 non-null   int64\n",
      " 12  cigarette cartons   4627 non-null   int64\n",
      " 13  cleaners-polishers  4627 non-null   int64\n",
      " 14  coffee              4627 non-null   int64\n",
      " 15  sauces-gravy-pkle   4627 non-null   int64\n",
      " 16  confectionary       4627 non-null   int64\n",
      " 17  puddings-deserts    4627 non-null   int64\n",
      " 18  dishcloths-scour    4627 non-null   int64\n",
      " 19  deod-disinfectant   4627 non-null   int64\n",
      " 20  frozen foods        4627 non-null   int64\n",
      " 21  razor blades        4627 non-null   int64\n",
      " 22  fuels-garden aids   4627 non-null   int64\n",
      " 23  spices              4627 non-null   int64\n",
      " 24  jams-spreads        4627 non-null   int64\n",
      " 25  insecticides        4627 non-null   int64\n",
      " 26  pet foods           4627 non-null   int64\n",
      " 27  laundry needs       4627 non-null   int64\n",
      " 28  party snack foods   4627 non-null   int64\n",
      " 29  tissues-paper prd   4627 non-null   int64\n",
      " 30  wrapping            4627 non-null   int64\n",
      " 31  dried vegetables    4627 non-null   int64\n",
      " 32  pkt-canned soup     4627 non-null   int64\n",
      " 33  soft drinks         4627 non-null   int64\n",
      " 34  health food other   4627 non-null   int64\n",
      " 35  beverages hot       4627 non-null   int64\n",
      " 36  health&beauty misc  4627 non-null   int64\n",
      " 37  deodorants-soap     4627 non-null   int64\n",
      " 38  mens toiletries     4627 non-null   int64\n",
      " 39  medicines           4627 non-null   int64\n",
      " 40  haircare            4627 non-null   int64\n",
      " 41  dental needs        4627 non-null   int64\n",
      " 42  lotions-creams      4627 non-null   int64\n",
      " 43  sanitary pads       4627 non-null   int64\n",
      " 44  cough-cold-pain     4627 non-null   int64\n",
      " 45  meat misc           4627 non-null   int64\n",
      " 46  cheese              4627 non-null   int64\n",
      " 47  chickens            4627 non-null   int64\n",
      " 48  milk-cream          4627 non-null   int64\n",
      " 49  cold-meats          4627 non-null   int64\n",
      " 50  deli gourmet        4627 non-null   int64\n",
      " 51  margarine           4627 non-null   int64\n",
      " 52  salads              4627 non-null   int64\n",
      " 53  small goods         4627 non-null   int64\n",
      " 54  dairy foods         4627 non-null   int64\n",
      " 55  fruit drinks        4627 non-null   int64\n",
      " 56  delicatessen misc   4627 non-null   int64\n",
      " 57  beef                4627 non-null   int64\n",
      " 58  hogget              4627 non-null   int64\n",
      " 59  lamb                4627 non-null   int64\n",
      " 60  pet food            4627 non-null   int64\n",
      " 61  pork                4627 non-null   int64\n",
      " 62  poultry             4627 non-null   int64\n",
      " 63  veal                4627 non-null   int64\n",
      " 64  gourmet meat        4627 non-null   int64\n",
      " 65  produce misc        4627 non-null   int64\n",
      " 66  fruit               4627 non-null   int64\n",
      " 67  plants              4627 non-null   int64\n",
      " 68  potatoes            4627 non-null   int64\n",
      " 69  vegetables          4627 non-null   int64\n",
      " 70  variety misc        4627 non-null   int64\n",
      " 71  brushware           4627 non-null   int64\n",
      " 72  electrical          4627 non-null   int64\n",
      " 73  haberdashery        4627 non-null   int64\n",
      " 74  kitchen             4627 non-null   int64\n",
      " 75  manchester          4627 non-null   int64\n",
      " 76  pantyhose           4627 non-null   int64\n",
      " 77  plasticware         4627 non-null   int64\n",
      " 78  stationary          4627 non-null   int64\n",
      " 79  prepared meals      4627 non-null   int64\n",
      " 80  preserving needs    4627 non-null   int64\n",
      " 81  condiments          4627 non-null   int64\n",
      " 82  cooking oils        4627 non-null   int64\n",
      " 83  bake off products   4627 non-null   int64\n",
      " 84  small goods2        4627 non-null   int64\n",
      " 85  offal               4627 non-null   int64\n",
      " 86  mutton              4627 non-null   int64\n",
      " 87  trim pork           4627 non-null   int64\n",
      " 88  trim lamb           4627 non-null   int64\n",
      " 89  imported cheese     4627 non-null   int64\n",
      " 90  casks white wine    4627 non-null   int64\n",
      " 91  casks red wine      4627 non-null   int64\n",
      " 92  750ml white nz      4627 non-null   int64\n",
      " 93  750ml red nz        4627 non-null   int64\n",
      " 94  750ml white imp     4627 non-null   int64\n",
      " 95  750ml red imp       4627 non-null   int64\n",
      " 96  sparkling nz        4627 non-null   int64\n",
      " 97  sparkling imp       4627 non-null   int64\n",
      " 98  port and sherry     4627 non-null   int64\n",
      " 99  non host support    4627 non-null   int64\n",
      "dtypes: int64(100)\n",
      "memory usage: 3.5 MB\n"
     ]
    }
   ],
   "source": [
    "supermarket.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2. Data Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Apriori Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Apriori class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Apriori:\n",
    "    def __init__(self, min_sup = 0.2):\n",
    "        self.min_sup = min_sup # min support\n",
    "        \n",
    "    '''\n",
    "    *Generating frequent 1-itemsets*\n",
    "    in: data<pandas.core.frame.DataFrame>\n",
    "    out: C<list>[<tuple>], D<dict>\n",
    "    '''\n",
    "    def _frequent_singleton(self, data):\n",
    "        sup_count = data.sum()\n",
    "        sup_count = sup_count[sup_count>=self.min_sup_count]\n",
    "        sup_count.index = [(idx,) for idx in sup_count.index]\n",
    "        C = sup_count.index\n",
    "        D = sup_count.to_dict()\n",
    "        return C, D\n",
    "    \n",
    "    '''\n",
    "    *Generating candidates*\n",
    "    in: l<list>[<tuple>], k<int>\n",
    "    out: <list>[<tuple>]\n",
    "    '''\n",
    "    def _apriori_gen(self, l, k): # l:frequent (k-1)-itemsets\n",
    "        C = set()\n",
    "        for i in range(len(l)-1):\n",
    "            for j in range(i+1,len(l)):\n",
    "                c = tuple(sorted(set(l[i]).union(set(l[j]))))\n",
    "                if (k == 2) or (len(c) == k) and not (self._has_infrequent_subset(c, l, k-1)):\n",
    "                    C.add(c)\n",
    "        return list(C)                \n",
    "    \n",
    "    '''\n",
    "    *Pruning*\n",
    "    in: c<tuple>, l<list>[<tuple>], k<int>\n",
    "    out: <boolean>\n",
    "    '''\n",
    "    def _has_infrequent_subset(self, c, l, k): # c: candidate k-itemset, L:frequent (k-1)-itemsets\n",
    "        S = self._ksubsets(set(c), k)\n",
    "        for s in S:\n",
    "            if tuple(sorted(s)) not in l:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    '''\n",
    "    *Generating all subsets of c with k elements*\n",
    "    in: c<set>, k<int>\n",
    "    out: <set> \n",
    "    '''\n",
    "    def _ksubsets(self, c, k):\n",
    "        import itertools\n",
    "        return set(itertools.combinations(c, k))\n",
    "    \n",
    "    '''\n",
    "    *Mining all frequent itemsets*\n",
    "    in: data<pandas.core.frame.DataFrame>\n",
    "    out: L<list>[<list>[<tuple>]]\n",
    "    '''\n",
    "    def mine(self, data):\n",
    "        import time\n",
    "        start_time = time.time()\n",
    "        self.min_sup_count = int(self.min_sup*data.shape[0])+1\n",
    "        C, D= self._frequent_singleton(data)\n",
    "        k = 1\n",
    "        while len(C) > 0:\n",
    "            C = self._apriori_gen(C, k+1)\n",
    "            for i in range(data.shape[0]):\n",
    "                transaction = data.loc[i]\n",
    "                s = set(transaction[transaction>0].index)\n",
    "                for c in C:\n",
    "                    if set(c).issubset(s):\n",
    "                        D[c] = D.get(c,0)+1\n",
    "            C = [c for c in C if D.get(c,0) >= self.min_sup_count]\n",
    "            k += 1\n",
    "        D = {key:val for key,val in D.items() if val >= self.min_sup_count}\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print('Time elapsed:', elapsed_time)\n",
    "        return D\n",
    "    \n",
    "    '''\n",
    "    *Showing top 10 most frequent 2,3,4-itemsets*\n",
    "    in: D<dict>\n",
    "    '''\n",
    "    def display(self, D):\n",
    "        for i in range(2,5):\n",
    "            print('Top 10 most frequent ', i, '-itemset:',sep='')\n",
    "            L = [item for item in D.items() if len(item[0])==i]\n",
    "            L = sorted(L, key = lambda item: float(item[1]), reverse = True)\n",
    "            for j in range(10):\n",
    "                print(j+1,': ', L[j], sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Pattern mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 32.38124108314514\n"
     ]
    }
   ],
   "source": [
    "apriori = Apriori(min_sup=0.2)\n",
    "D = apriori.mine(supermarket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3 Frequent patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most frequent 2-itemset:\n",
      "1: (('bread and cake', 'milk-cream'), 2337)\n",
      "2: (('bread and cake', 'fruit'), 2325)\n",
      "3: (('bread and cake', 'vegetables'), 2298)\n",
      "4: (('fruit', 'vegetables'), 2207)\n",
      "5: (('baking needs', 'bread and cake'), 2191)\n",
      "6: (('bread and cake', 'frozen foods'), 2129)\n",
      "7: (('biscuits', 'bread and cake'), 2083)\n",
      "8: (('fruit', 'milk-cream'), 2038)\n",
      "9: (('milk-cream', 'vegetables'), 2025)\n",
      "10: (('baking needs', 'vegetables'), 1949)\n",
      "Top 10 most frequent 3-itemset:\n",
      "1: (('bread and cake', 'fruit', 'vegetables'), 1791)\n",
      "2: (('bread and cake', 'fruit', 'milk-cream'), 1684)\n",
      "3: (('bread and cake', 'milk-cream', 'vegetables'), 1658)\n",
      "4: (('baking needs', 'bread and cake', 'vegetables'), 1586)\n",
      "5: (('baking needs', 'bread and cake', 'milk-cream'), 1580)\n",
      "6: (('fruit', 'milk-cream', 'vegetables'), 1571)\n",
      "7: (('baking needs', 'bread and cake', 'fruit'), 1564)\n",
      "8: (('bread and cake', 'frozen foods', 'vegetables'), 1548)\n",
      "9: (('bread and cake', 'frozen foods', 'fruit'), 1548)\n",
      "10: (('biscuits', 'bread and cake', 'fruit'), 1541)\n",
      "Top 10 most frequent 4-itemset:\n",
      "1: (('bread and cake', 'fruit', 'milk-cream', 'vegetables'), 1311)\n",
      "2: (('baking needs', 'bread and cake', 'fruit', 'vegetables'), 1255)\n",
      "3: (('bread and cake', 'frozen foods', 'fruit', 'vegetables'), 1242)\n",
      "4: (('biscuits', 'bread and cake', 'fruit', 'vegetables'), 1216)\n",
      "5: (('baking needs', 'bread and cake', 'milk-cream', 'vegetables'), 1169)\n",
      "6: (('baking needs', 'bread and cake', 'fruit', 'milk-cream'), 1161)\n",
      "7: (('biscuits', 'bread and cake', 'frozen foods', 'fruit'), 1143)\n",
      "8: (('bread and cake', 'frozen foods', 'fruit', 'milk-cream'), 1138)\n",
      "9: (('bread and cake', 'frozen foods', 'milk-cream', 'vegetables'), 1131)\n",
      "10: (('biscuits', 'bread and cake', 'fruit', 'milk-cream'), 1122)\n"
     ]
    }
   ],
   "source": [
    "apriori.display(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 FP-growth Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Header class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, item, sup):\n",
    "        self.item = item\n",
    "        self.sup = sup\n",
    "        self.adjacent = None\n",
    "        self.tail = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Tree class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class treeNode:\n",
    "    def __init__(self, item, count=1):\n",
    "        self.item = item\n",
    "        self.count = count\n",
    "        self.parent = None\n",
    "        self.next = None\n",
    "        self.child = set()\n",
    "    \n",
    "    def single_path(self):\n",
    "        temp = self\n",
    "        while len(temp.child)>0:\n",
    "            if len(temp.child)>1:\n",
    "                return False\n",
    "            temp = tuple(temp.child)[0]\n",
    "        return True\n",
    "\n",
    "    def insert_tree(self, header, transaction, i, count = 1):\n",
    "        if i >= len(transaction):\n",
    "            return\n",
    "        head = None\n",
    "        for node in header:\n",
    "            if node.item == transaction[i]:\n",
    "                head = node\n",
    "                break\n",
    "        if head == None:\n",
    "            return\n",
    "        for c in self.child:\n",
    "            if c.item == transaction[i]:\n",
    "                c.count += count\n",
    "                c.insert_tree(header,transaction, i+1, count)\n",
    "                return\n",
    "        c = self.__class__(transaction[i],count)\n",
    "        c.parent = self\n",
    "        self.child.add(c)\n",
    "        if head.adjacent == None:\n",
    "            head.tail = head.adjacent = c\n",
    "        else:\n",
    "            head.tail.next = c\n",
    "            head.tail = head.tail.next\n",
    "        c.insert_tree(header,transaction, i+1, count)\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 FP-tree class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FP_tree:\n",
    "    def __init__(self,header, tree):\n",
    "        self.header = header\n",
    "        self.tree = tree\n",
    "        \n",
    "    '''\n",
    "    *Generating conditional pattern base*\n",
    "    in: item<str>\n",
    "    out: pattern_base<dict>\n",
    "    '''\n",
    "    def _cond_pattern_base(self, item):\n",
    "        pattern_base = dict()\n",
    "        for node in self.header:\n",
    "            if node.item == item:\n",
    "                break\n",
    "        head = node.adjacent\n",
    "        while True:\n",
    "            temp = head\n",
    "            l = list()\n",
    "            while temp.parent.item != '':\n",
    "                l.append(temp.parent.item)\n",
    "                temp = temp.parent\n",
    "            if len(l) > 0:\n",
    "                l.reverse()\n",
    "                pattern_base[tuple(l)] = head.count\n",
    "            if head.next == None:\n",
    "                break\n",
    "            head = head.next\n",
    "        return pattern_base\n",
    "        \n",
    "    '''\n",
    "    *Generating conditional FP-tree*\n",
    "    in: item<str>, min_sup_count<int>\n",
    "    out: <FP-tree>\n",
    "    '''\n",
    "    def cond_FP_tree(self, item, min_sup_count):\n",
    "        cpb = self._cond_pattern_base(item)\n",
    "        root = treeNode('',0)\n",
    "        header = dict()\n",
    "        for itemset in cpb:\n",
    "            for item in itemset:\n",
    "                header[item] = header.get(item,0) + cpb[itemset]\n",
    "        header = [Node(key,val) for key,val in header.items() if val >= min_sup_count]        \n",
    "        for itemset in cpb:\n",
    "            root.insert_tree(header, itemset, 0, cpb[itemset])\n",
    "        return FP_tree(header, root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 FP-growth class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FP_growth:\n",
    "    def __init__(self, min_sup = 0.2):\n",
    "        self.min_sup = min_sup\n",
    "    \n",
    "    '''\n",
    "    *Generating frequent 1-itemsets*\n",
    "    in: data<pandas.core.frame.DataFrame>\n",
    "    out: header<list>[<Node>], D<dict>\n",
    "    '''\n",
    "    def _frequent_item(self, data):\n",
    "        sup_count = data.sum()\n",
    "        sup_count = sup_count[sup_count >= self.min_sup_count]\n",
    "        sup_count = sup_count.sort_values(ascending=False)\n",
    "        header = [Node(item,sup_count[item]) for item in sup_count.index]\n",
    "        sup_count.index = [(idx,) for idx in sup_count.index]\n",
    "        D = sup_count.to_dict()\n",
    "        return header, D\n",
    "    \n",
    "    '''\n",
    "    *Constructing tree*\n",
    "    in: header<list>[<Node>], data<pandas.core.frame.DataFrame>\n",
    "    out: root<treeNode>\n",
    "    '''        \n",
    "    def _construct_tree(self, header, data):\n",
    "        root = treeNode('',0)\n",
    "        for i in range(data.shape[0]):\n",
    "            transaction = data.loc[i] \n",
    "            transaction = [node.item for node in header if transaction[node.item] > 0]\n",
    "            root.insert_tree(header, transaction, 0)\n",
    "        return root\n",
    "    \n",
    "    '''\n",
    "    *Implementing FP-growth*\n",
    "    in: fp_tree<FP-tree>, pattern<list>\n",
    "    out: D<dict>\n",
    "    '''    \n",
    "    def _FP_growth(self, fp_tree, pattern):\n",
    "        import itertools\n",
    "        D = dict()\n",
    "        if fp_tree.tree.single_path():\n",
    "            temp = fp_tree.tree\n",
    "            l = list()\n",
    "            d = dict()\n",
    "            while len(temp.child) > 0:\n",
    "                c = tuple(temp.child)[0]\n",
    "                l.append(c.item)\n",
    "                d[c.item] = c.count\n",
    "                temp = c\n",
    "            for i in range(0,len(l)):\n",
    "                combination = list(itertools.combinations(l,i+1))\n",
    "                for itemset in combination:\n",
    "                    sup_count = d[itemset[-1]]\n",
    "                    itemset = list(itemset)+ pattern\n",
    "                    D[tuple(itemset)] = sup_count\n",
    "        else:\n",
    "            for node in fp_tree.header:\n",
    "                cfpt = fp_tree.cond_FP_tree(node.item, self.min_sup_count)\n",
    "                D[tuple([node.item]+pattern)] = node.sup\n",
    "                if len(cfpt.tree.child) > 0:\n",
    "                    D = {**D,**self._FP_growth(cfpt, [node.item]+pattern)}\n",
    "        return D \n",
    "        \n",
    "    '''\n",
    "    *Mining all frequent itemsets*\n",
    "    in: data<pandas.core.frame.DataFrame>\n",
    "    out: <dict>\n",
    "    '''\n",
    "    def mine(self,data):\n",
    "        import time\n",
    "        start_time = time.time()\n",
    "        self.min_sup_count = int(self.min_sup*data.shape[0])+1\n",
    "        header, self.D = self._frequent_item(data) # D may be unnecessary\n",
    "        tree = self._construct_tree(header,data)\n",
    "        fp_tree = FP_tree(header, tree)\n",
    "        self.D = {**self.D,**self._FP_growth(fp_tree,[])}\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print('Time elapsed:', elapsed_time)\n",
    "        return self.D\n",
    "    \n",
    "    '''\n",
    "    *Showing top 10 most frequent 2,3,4-itemsets*\n",
    "    in: D<dict>\n",
    "    '''\n",
    "    def display(self,D):\n",
    "        for i in range(2,5):\n",
    "            print('Top 10 most frequent ', i, '-itemset:',sep='')\n",
    "            L = [(tuple(sorted(item[0])),item[1]) for item in D.items() if len(item[0])==i]\n",
    "            L = sorted(L, key = lambda item: float(item[1]), reverse = True)\n",
    "            for j in range(10):\n",
    "                print(j+1,': ', L[j], sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.5 Pattern mining "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 5.522256135940552\n"
     ]
    }
   ],
   "source": [
    "fp_growth = FP_growth(min_sup=0.2)\n",
    "D = fp_growth.mine(supermarket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.6 Frequent patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most frequent 2-itemset:\n",
      "1: (('bread and cake', 'milk-cream'), 2337)\n",
      "2: (('bread and cake', 'fruit'), 2325)\n",
      "3: (('bread and cake', 'vegetables'), 2298)\n",
      "4: (('fruit', 'vegetables'), 2207)\n",
      "5: (('baking needs', 'bread and cake'), 2191)\n",
      "6: (('bread and cake', 'frozen foods'), 2129)\n",
      "7: (('biscuits', 'bread and cake'), 2083)\n",
      "8: (('fruit', 'milk-cream'), 2038)\n",
      "9: (('milk-cream', 'vegetables'), 2025)\n",
      "10: (('baking needs', 'vegetables'), 1949)\n",
      "Top 10 most frequent 3-itemset:\n",
      "1: (('bread and cake', 'fruit', 'vegetables'), 1791)\n",
      "2: (('bread and cake', 'fruit', 'milk-cream'), 1684)\n",
      "3: (('bread and cake', 'milk-cream', 'vegetables'), 1658)\n",
      "4: (('baking needs', 'bread and cake', 'vegetables'), 1586)\n",
      "5: (('baking needs', 'bread and cake', 'milk-cream'), 1580)\n",
      "6: (('fruit', 'milk-cream', 'vegetables'), 1571)\n",
      "7: (('baking needs', 'bread and cake', 'fruit'), 1564)\n",
      "8: (('bread and cake', 'frozen foods', 'fruit'), 1548)\n",
      "9: (('bread and cake', 'frozen foods', 'vegetables'), 1548)\n",
      "10: (('biscuits', 'bread and cake', 'fruit'), 1541)\n",
      "Top 10 most frequent 4-itemset:\n",
      "1: (('bread and cake', 'fruit', 'milk-cream', 'vegetables'), 1311)\n",
      "2: (('baking needs', 'bread and cake', 'fruit', 'vegetables'), 1255)\n",
      "3: (('bread and cake', 'frozen foods', 'fruit', 'vegetables'), 1242)\n",
      "4: (('biscuits', 'bread and cake', 'fruit', 'vegetables'), 1216)\n",
      "5: (('baking needs', 'bread and cake', 'milk-cream', 'vegetables'), 1169)\n",
      "6: (('baking needs', 'bread and cake', 'fruit', 'milk-cream'), 1161)\n",
      "7: (('biscuits', 'bread and cake', 'frozen foods', 'fruit'), 1143)\n",
      "8: (('bread and cake', 'frozen foods', 'fruit', 'milk-cream'), 1138)\n",
      "9: (('bread and cake', 'frozen foods', 'milk-cream', 'vegetables'), 1131)\n",
      "10: (('biscuits', 'bread and cake', 'fruit', 'milk-cream'), 1122)\n"
     ]
    }
   ],
   "source": [
    "fp_growth.display(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "under `min_sup`=0.2, FP-growth algorithm (~6s) runs almost five times faster than Apriori algorithm (>30s).\n",
    "\n",
    "Different from the multiple scans of data in Apriori, FP-growth only scans the data twice and boosts the speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "The end "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('virtual': venv)",
   "language": "python",
   "name": "python361064bitvirtualvenv17b58f63dd9043ed85793e7f8be03798"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
